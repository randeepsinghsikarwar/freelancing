{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urG_6owfqwuS"
   },
   "source": [
    "## Part 1 - Dealing with Missing Data\n",
    "\n",
    "\n",
    "**Notice: This notebook is a modification of [sniff.ipynb](https://mlbook.explained.ai/notebooks/index.html) by Terence Parr and Jeremy Howard, which was used by permission of the author.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tcl3KFEXqwuT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from rfpimp_MC import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4yf5yzsqwuU"
   },
   "source": [
    "We will use slightly modified versions of the `evaluate` and `showimp` functions from the last few notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x13zTYO3qwuU"
   },
   "outputs": [],
   "source": [
    "def evaluate(X, y, n_estimators=50):\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, n_jobs=-1, oob_score=True)\n",
    "    rf.fit(X, y)\n",
    "    oob = rf.oob_score_\n",
    "    n = rfnnodes(rf)\n",
    "    h = np.median(rfmaxdepths(rf))\n",
    "    print(f\"OOB R^2 is {oob:.5f} using {n:,d} tree nodes with {h} median tree depth\")\n",
    "    return rf, oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qj3GJ3jqqwuU"
   },
   "outputs": [],
   "source": [
    "def showimp(rf, X, y):\n",
    "    features = list(X.columns)\n",
    "    I = importances(rf, X, y, features=features)\n",
    "    plot_importances(I, color='#4575b4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkxZmXgdqwuU"
   },
   "source": [
    "### Read in the Data\n",
    "\n",
    "To prep the data for loading, please refer to [Section 7.1](https://mlbook.explained.ai/bulldozer-intro.html#sec:7.1) of *The Mechanics of Machine learning*. Once we have the data in the proper format, we are going to read it in and make a copy. Making a copy is a good idea as then we will always have the original data available without having to reload it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "l951ilWnqwuU",
    "outputId": "a5319b1e-95de-40d4-e71f-f003fb3cb64d"
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_feather(\"bulldozer-train.feather\")\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpIqcKZ9qwuU"
   },
   "source": [
    "Now let's see how much data we are dealing wih:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTpBHWLRqwuU"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RK6jaIFNqwuU"
   },
   "source": [
    "And get an idea of what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wdas1ynUqwuU"
   },
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUWcfpp2qwuV"
   },
   "source": [
    "Let's get a bit more information on the data so we can start planning what we need to do. To do this, we will use the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7F60ctRqwuV"
   },
   "outputs": [],
   "source": [
    "def sniff_modified(df):\n",
    "    with pd.option_context(\"display.max_colwidth\", 20):\n",
    "        info = pd.DataFrame()\n",
    "        info['data type'] = df.dtypes\n",
    "        info['percent missing'] = df.isnull().sum()*100/len(df)\n",
    "        info['No. unique'] = df.apply(lambda x: len(x.unique()))\n",
    "        info['unique values'] = df.apply(lambda x: x.unique())\n",
    "        return info.sort_values('data type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0uqYKR2qwuV"
   },
   "outputs": [],
   "source": [
    "sniff_modified(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yn-C-mzDqwuV"
   },
   "source": [
    "### Quickly get a Baseline Model\n",
    "\n",
    "As we did before, we need to specify our target (`SalePrice`) and then focus in on the numeric data and create and evaluate a baseline model. That means we will consider only these features for now: `SalesID`, `MachineID`, `ModelID`, `datasource`, `YearMade`, `auctioneerID`, and `MachineHoursCurrentMeter`. \n",
    "\n",
    "However, as seen above, the last two contain missing values, so we will have to deal with that in order to create a model. \n",
    "\n",
    "Remember that we need two things to train a model:\n",
    "- all numeric data\n",
    "- no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RS5Uw5xDqwuV"
   },
   "outputs": [],
   "source": [
    "basefeatures = ['SalesID', 'MachineID', 'ModelID',\n",
    "                'datasource', 'YearMade',\n",
    "                'auctioneerID', 'MachineHoursCurrentMeter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEHrBRIHqwuV"
   },
   "outputs": [],
   "source": [
    "X = df[basefeatures]\n",
    "y = df['SalePrice']\n",
    "\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDcg6uq8qwuV"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf, oob_baseline_initial = evaluate(X, y, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HP8dMZc-qwuV"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf, oob_baseline_initial = evaluate(X, y, n_estimators=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_HED_NJqwuV"
   },
   "source": [
    "To speed up the training time even further, we will only work with a portion of the data: 100,000 samples. If the data had no time sensitivity, then we would take a random sample. Since we have time sensitive data we will take the last 100,000 samples as more recent data should be better at predicting near future sale prices, since we know that prices can change over time due to inflation, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrnlwBaaqwuV"
   },
   "outputs": [],
   "source": [
    "df = df.iloc[-100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMrmCMBKqwuV"
   },
   "outputs": [],
   "source": [
    "X = df[basefeatures]\n",
    "y = df['SalePrice']\n",
    "\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugQ21IyNqwuV"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf, oob_baseline_initial = evaluate(X, y, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Qu8oMAbqwuV"
   },
   "outputs": [],
   "source": [
    "showimp(rf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1j0rANv5qwuV"
   },
   "source": [
    "### Cleaning up the Data\n",
    "\n",
    "In order to try to improve our model performance (which may or may not be possible) we will clean up our data with the following procedure:\n",
    "- Drop features that have no predictive value or have known problems that can't be fixed;\n",
    "- Convert actual categorical features from current numeric data type to an object data type;\n",
    "- normalize the representation of missing data;\n",
    "- clean up strings that are actually numeric; \n",
    "- extract features;\n",
    "- encode categorical features; \n",
    "- deal with missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xik6kcVqwuW"
   },
   "source": [
    "#### Removing Features\n",
    "\n",
    "Let's start with features we can get rid of: \n",
    "\n",
    "- `SalesID` can be deleted as it is a unique identifier, that is, each row in the data has a unique value for `SalesID` so our model will not be able to use this to help it generalize; \n",
    "- `MachineID` should be deleted as it can be shown to have inconsistencies and errors, as in the same `MachineID` showing up as being manufactured in many different years (see link in [Section 7.4](https://mlbook.explained.ai/bulldozer-intro.html#sec:7.4) for details).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riwWXMb9qwuW"
   },
   "outputs": [],
   "source": [
    "df.drop(['SalesID', 'MachineID'], axis=1, inplace=True)\n",
    "# df = df.drop(['SalesID', 'MachineID'], axis=1)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8xgXiszqwuW"
   },
   "source": [
    "#### Convert DataType\n",
    "\n",
    "Sometimes what are really categorical variables show up in our data as numeric, so we need to figure out how to handle these situations. Of our original numeric data, it seems that we have a few that are categorical:\n",
    "\n",
    "- `ModelID` is a nominal categorical feature but it is already encoded as a number and has no missing values so we will leave it as it is;\n",
    "- `datasource` is a nominal categorical feature but it is already encoded as a number and has no missing values so we will leave it as it is;\n",
    "- `auctioneerID` is a nominal categorical feature and since it has missing values we will convert this to an *object* data type and deal with it when we handle categorical encoding and missing values.\n",
    "\n",
    "So, for now we will simply convert `auctioneerID` from numeric to string data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KC_OqfkeqwuW"
   },
   "outputs": [],
   "source": [
    "df['auctioneerID'] = df['auctioneerID'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkJtydt6qwuW"
   },
   "source": [
    "#### What does *missing* mean?\n",
    "\n",
    "The concept of missing is not usually straightforward so you will have to do some digging into the data to see what you find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jO_WLreQqwuW"
   },
   "outputs": [],
   "source": [
    "missing = pd.DataFrame({'colour':['Unspecified', 'red', None, '', 'None', 'yellow'], 'width':[ 12, -1, '', 14, 999, np.nan]})\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHLI5dMxqwuW"
   },
   "outputs": [],
   "source": [
    "missing.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPKsoTa3qwuW"
   },
   "source": [
    "#### How Missing is Represented in Our Data\n",
    "\n",
    "Let's see how missing values are showing up in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWTF_dvxqwuW"
   },
   "outputs": [],
   "source": [
    "df['Drive_System'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpMyLa4VqwuW"
   },
   "outputs": [],
   "source": [
    "df['Backhoe_Mounting'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bN9r1PZqwuW"
   },
   "outputs": [],
   "source": [
    "df['fiModelSeries'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0KtMSvGqwuW"
   },
   "source": [
    "#### Normalize the Representation of Missing Values\n",
    "\n",
    "It will be much easier to handle if we convert all the different ways this data has to signal missing data down to a single representation: `np.nan`. To do this we will use the following function which: \n",
    "- converts all strings (text) to lower case;\n",
    "- fill actual missing data with `np.nan`; the impact of this is to convert `None` to `np.nan`;\n",
    "- convert all the other representations ('none', 'none or unspecified', '#name?', and '') to `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_GlOGqhqwuW"
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import is_string_dtype, is_object_dtype\n",
    "\n",
    "def df_normalize_strings(df):\n",
    "    for col in df.columns:\n",
    "        if is_string_dtype(df[col]) or is_object_dtype(df[col]):\n",
    "            df[col] = df[col].str.lower()\n",
    "            df[col] = df[col].fillna(np.nan)\n",
    "            df[col] = df[col].replace('none or unspecified', np.nan)\n",
    "            df[col] = df[col].replace('none', np.nan)\n",
    "            df[col] = df[col].replace('#name?', np.nan)\n",
    "            df[col] = df[col].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rq3rJf7RqwuW"
   },
   "outputs": [],
   "source": [
    "df_normalize_strings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AklT2WAKqwuW"
   },
   "outputs": [],
   "source": [
    "df['Drive_System'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTF0To9pqwuW"
   },
   "outputs": [],
   "source": [
    "df['Backhoe_Mounting'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wU_IEgpVqwuW"
   },
   "outputs": [],
   "source": [
    "df['fiModelSeries'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IshOZLfqwuW"
   },
   "source": [
    "#### Numeric Features Hiding as Strings\n",
    "\n",
    "Some of the features that are being stored as strings are actually numeric: `TireSize`, `Undercarriage_Pad_Width`, `Blade_Width`, and `Stick_Length`. The first two are easier so let's look at them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZ13HEbaqwuW"
   },
   "outputs": [],
   "source": [
    "df['Tire_Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_P5_KqOpqwuX"
   },
   "outputs": [],
   "source": [
    "df['Undercarriage_Pad_Width'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = '36 inch'.split()\n",
    "int(m[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0iSg_OIqwuX"
   },
   "source": [
    "For these two we are going to: \n",
    "- extract numbers using a regular expression;\n",
    "- replace any resulting missing value with `np.nan` (just in case);\n",
    "- convert the column to numeric data type.\n",
    "\n",
    "To see how regular expressions are going to work for us, let's use a toy dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPuj7GP6qwuX"
   },
   "outputs": [],
   "source": [
    "regexp = pd.DataFrame({'Tire_Size':['12', 'some text 14 some text', '13\"', '12.5\"']})\n",
    "regexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-qc9JTaqwuX"
   },
   "outputs": [],
   "source": [
    "regexp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ltcfd5kr0Ib"
   },
   "source": [
    "Now let's use a regular expression to extract the types of numbers we expect to see in the `Tire_Size` feature. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIuwsrjpqwuX"
   },
   "outputs": [],
   "source": [
    "regexp['Tire_Size'] = regexp['Tire_Size'].str.extract(r'(\\d+\\.\\d+|\\d+)') \n",
    "regexp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ur2e8qut3q-"
   },
   "source": [
    "In the `extract('(\\d+\\.\\d+|\\d+)')` code above we have the following basic elements:\n",
    "\n",
    "- `\\d+` to extract any sequence of digits, e.g., '12', '123', '1234'; \n",
    "- `\\.` to extract a literal decimal point '.'; and, \n",
    "- `|` is the OR operator. \n",
    "\n",
    "These basic elements are used in the following way: \n",
    "- `\\d+\\.\\d+` to extract any sequence of one or more digits followed by a decimal point followed by another sequence of one or more digits; OR \n",
    "- `\\d+` to extract any sequence of one or more digits when there is no decimal point. \n",
    "\n",
    "We should also notice that extract the numbers does not mean that the column has been converted to a numeric data type. So far, we have just cleaned up the strings that represent numbers so that all non-numeric characters (like \" as the shorthand notation for inches) have been removed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIitO8bPqwuX"
   },
   "outputs": [],
   "source": [
    "regexp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0kWXhYdvRhV"
   },
   "source": [
    "We need to explicitly convert the feature to a numeric data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dwK1NXTvP7J"
   },
   "outputs": [],
   "source": [
    "regexp['Tire_Size'] = pd.to_numeric(regexp['Tire_Size'])\n",
    "regexp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBoq-hCcvG8B"
   },
   "source": [
    "We will now create a function to do this for any feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddpVMLgsqwuX"
   },
   "outputs": [],
   "source": [
    "def extract_sizes(df, colname):\n",
    "    df[colname] = df[colname].str.extract(r'(\\d+\\.\\d+|\\d+)', expand=True)\n",
    "    df[colname] = df[colname].replace('', np.nan)\n",
    "    df[colname] = pd.to_numeric(df[colname])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5KJbCOfxJvP"
   },
   "source": [
    "We can now apply this function to `Tire_Size` and `Undercarriage_Pad_Width`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tire_Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvyPvEBdxai1"
   },
   "outputs": [],
   "source": [
    "extract_sizes(df, 'Tire_Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tire_Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUEq3xK2xmN7"
   },
   "outputs": [],
   "source": [
    "extract_sizes(df, 'Undercarriage_Pad_Width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EmGoBw6xse1"
   },
   "source": [
    "Dealing with `Blade_Width` is a bit more complicated because of the `\"<12'\"` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVsx6AoZz7m8"
   },
   "outputs": [],
   "source": [
    "df['Blade_Width'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JliS1frJ0HZ7"
   },
   "source": [
    "There are a couple ways to approach this: \n",
    "- convert it into numeric form; or \n",
    "- consider this to be a categorical variable given the small number of unique values. \n",
    "\n",
    "This feature has missing values so we have to consider that as well. If we convert it to numeric we will end up replacing the missing values with a median value. And if we treat it as categorical, then the missing values will form their own category. \n",
    "\n",
    "We will treat this as a categorical variable but the next section shows how you could go about converting it to numeric if you chose to do that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhaA0drC2Ofi"
   },
   "source": [
    "##### Aside: convert `Blade_Width` to numeric\n",
    "\n",
    "To demonstrate this will will use a toy dataset that consists of all the unique values found in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNKB0JMGxhZ4"
   },
   "outputs": [],
   "source": [
    "blade = pd.DataFrame({'width':[np.nan, \"12'\", \"14'\", \"13'\", \"16'\", \"<12'\"]})\n",
    "blade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ixV7RTp2em6"
   },
   "source": [
    "Since there aren't that many unique values, we can create a mapping that directly converts all the values to their corresponding number. Here, I am grouping all the `\"<12'\"` under the number 11. This may not be ideal as that will impact the median value when we replace the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4_7lM2-yKlc"
   },
   "outputs": [],
   "source": [
    "blade['width'] = blade['width'].map({\"NaN\": np.nan, \"12'\":12, \"13'\": 13, \"14'\":14, \"16'\":16, \"<12'\":11})\n",
    "blade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61V7Tjdxzayi"
   },
   "outputs": [],
   "source": [
    "blade.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stick_Length'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTD2_YST3V3l"
   },
   "source": [
    "`Stick_Length` is similar to `Blade_Width` and we could handle it in the same way. However, in this case I am going to try to convert it numeric `apply()` and a new function. Aside from the missing values, the entries for this feature all have the same structure: `'10\\'6\"'`. The outer quotations (' ') tell us this is a string, while the middle `\\'` is a single literal quotation that is shorthand for the distance measurement of `feet` and the single \" is shorthand for `inches`. \n",
    "\n",
    "The steps we'll need to take are: \n",
    "- extract the number for feet and the number for inches; \n",
    "- multiply the number of feet by 12 to convert to inches; and \n",
    "- add it to the number of inches. \n",
    "This will convert the `Stick_Length` feature to a numeric column where the unit of length is the inch. \n",
    "\n",
    "To see how this is going to work we will create a toy dataframe using the unique values for `Stick_Length`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iu_cwMNPzcji"
   },
   "outputs": [],
   "source": [
    "stick = pd.DataFrame({'length': df['Stick_Length'].unique()})\n",
    "                      \n",
    "stick.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eB8nVZ0h7h0m"
   },
   "outputs": [],
   "source": [
    "stick.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5O1yn2v7Lgq"
   },
   "outputs": [],
   "source": [
    "# modified version of: https://stackoverflow.com/questions/26986655/changing-height-feet-and-inches-to-an-integer-in-python-pandas\n",
    "\n",
    "def parse_length(length):\n",
    "    if not pd.isnull(length):\n",
    "      split_length = length.split(\"' \")\n",
    "      feet = float(split_length[0])\n",
    "      inches = float(split_length[1].replace(\"\\\"\",\"\"))\n",
    "      return (12*feet) + inches\n",
    "    else:\n",
    "      return np.nan\n",
    "\n",
    "stick['length'] = stick[\"length\"].apply(lambda x: parse_length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWyKEW3jRRUP"
   },
   "outputs": [],
   "source": [
    "stick.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8z9Q-NQ4RfUd"
   },
   "outputs": [],
   "source": [
    "stick.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7o_MHJ9LJtVO"
   },
   "source": [
    "### Summary\n",
    "\n",
    "It is a good time to recall everything that we have done so far. We have:\n",
    "\n",
    "- dropped the `SalesID` and `MachineID` features;\n",
    "- converted `auctioneerID` to 'string' data type so we can treat it as a categorical feature;\n",
    "- decided to leave `Blade_Width` as 'string' and treat as a categorical feature instead of converting to numeric;\n",
    "- extracted numeric features from the original `Undercarriage_Pad_Width` and `Tire_Size` strings;\n",
    "- converted `Stick_Length` to a numeric feature from the original string representation;\n",
    "- normalized the representation of missing values to `np.nan`.\n",
    "\n",
    "Since this process gets messy and, at times, difficult to keep track of, let's reproduce everything we've done so we can see it all in one place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "l951ilWnqwuU",
    "outputId": "a5319b1e-95de-40d4-e71f-f003fb3cb64d"
   },
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "df = df.iloc[-100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['SalesID', 'MachineID'], axis=1, inplace=True)\n",
    "df['auctioneerID'] = df['auctioneerID'].astype(str)\n",
    "df_normalize_strings(df)\n",
    "extract_sizes(df, 'Tire_Size')\n",
    "extract_sizes(df, 'Undercarriage_Pad_Width')\n",
    "df['Stick_Length'] = df['Stick_Length'].apply(lambda x: parse_length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YpgRhGvOqET"
   },
   "outputs": [],
   "source": [
    "sniff_modified(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Missing_Data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
